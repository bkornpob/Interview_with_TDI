{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Sample t-Test Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "After this lecture, students will be able to:\n",
    "\n",
    "1. describe what hypothesis testing is\n",
    "\n",
    "2. discuss the use of one-sample t-test hypothesis testing\n",
    "\n",
    "3. describe procedure performing one-sample t-test hypothesis testing\n",
    "\n",
    "4. perform one-sample t-test hypothesis testing using python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################################################################################################\n",
    "############################################ Preamble ################################################################\n",
    "######################################################################################################################\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from IPython.display import HTML\n",
    "\n",
    "##########################################\n",
    "######### Code folding script ############\n",
    "##########################################\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample mean = 50.53 \n",
      "Sample variance = 88.39 \n",
      "Sample size = 65\n"
     ]
    }
   ],
   "source": [
    "######################################################################################################################\n",
    "############################################ Simulate a sample #######################################################\n",
    "######################################################################################################################\n",
    "pop_mean = 50. # population mean\n",
    "pop_std = 10. # population standard deviation\n",
    "sample_size = 65 # sample size\n",
    "seed = 1234 # random seed\n",
    "np.random.seed(seed) # set seed\n",
    "sample = np.random.normal(pop_mean,pop_std,sample_size) # simulate\n",
    "\n",
    "###########################################\n",
    "############ Histogram of the sample ######\n",
    "###########################################\n",
    "plt.figure()\n",
    "plt.hist(sample)\n",
    "plt.show()\n",
    "\n",
    "###########################################\n",
    "############ Sample statistics ############\n",
    "###########################################\n",
    "sample_mean = sample.mean()\n",
    "sample_var = sample.var(ddof=1)\n",
    "print('Sample mean = {0:.2f} \\nSample variance = {1:.2f} \\nSample size = {2}'.format(sample_mean,sample_var,sample_size))\n",
    "\n",
    "######################################################################################################################\n",
    "############################################ Hypothesis testing ######################################################\n",
    "######################################################################################################################\n",
    "test_mean = 60. # target value\n",
    "alpha = 0.05 # significance level\n",
    "tscore = stats.ttest_1samp(sample,test_mean) # calculate sample t score\n",
    "tcrit = stats.t.ppf(alpha/2,sample_size-1) # calculate critical t score\n",
    "confidence_interval = stats.t.interval(1-alpha, sample_size-1 # calculate confidence interval\n",
    "                                       , loc=sample_mean, scale=np.sqrt(sample_var/sample_size))\n",
    "\n",
    "######################################################################################################################\n",
    "############################################ Calculate beta ##########################################################\n",
    "######################################################################################################################\n",
    "tscore_beta_left = (confidence_interval[0] - pop_mean)/np.sqrt(sample_var/sample_size)\n",
    "tscore_beta_right = (confidence_interval[1] - pop_mean)/np.sqrt(sample_var/sample_size)\n",
    "cdf_beta_left = stats.t.cdf(tscore_beta_left,sample_size-1)\n",
    "cdf_beta_right = stats.t.cdf(tscore_beta_right,sample_size-1)\n",
    "beta = cdf_beta_right - cdf_beta_left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "test_mean": "60.0"
    }
   },
   "source": [
    "## Overview\n",
    "\n",
    "This lecture focuses on performing one-sample t-test hypothesis testing (t-test for short) using python. We will work with a simulated sample shown in the histogram. From the sample, we would like to verify whether the sample mean is indifference to {{test_mean}}. Following in this lecture, we will verify the statement with three different methods: i) comparing sample t score to critical t score, ii) constructing a confidence interval, and iii) applying p-value. These three methods will lead to the same verification. \n",
    "\n",
    "This lecture is organized by first discussing theory and mathematics behind the technique. We will go through each step by performing manual calculation. Afterwards, the python code routine would be discussed.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "This lecture assumes students being familiar with basic concept of probability, and distribution function, especially, Student's t distribution. Also, students should already understand how to calculate sample mean and variance, interpret the area under the curve of a density function, and understand the two types of error. Basic knowledge of using python is also required if one would like to perform the t-test by following the code routine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "\n",
    "A hypothesis testing is performed in order to verify what conclusion should be made regarding to the properties of the data, and at how much likelihood that the conclusion might be wrong. For example, we might want to verify if we can conclude that the sample mean is statistically indifference to a certain value, or to other samples.\n",
    "\n",
    "There are various types of hypothesis testing. Each type has its own strength, weakness, and assumptions that must be satisfied. In a broad sense, we can classify hypothesis testing methods into parametric and nonparametric. The difference between the two is that nonparametric method does not assume distribution properties of a sample, while parametric method does. In this lecture, we will focus on the one-sample t-test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumptions\n",
    "\n",
    "In one-sample t-test, we require the following assumptions to be satisfied in order that the method will provide a valid result:\n",
    "1. the random variables (i.e., $x_1,...,x_N$) being continuous from negative to positive infinity, \n",
    "2. independently and identically distributed (i.i.d.) of the random variables which simply means each data point is drawn from the same distribution independently of other data points,\n",
    "3. normal distribution of sample means, and\n",
    "4. unknown population variance and applying sample variance in the estimation instead.\n",
    "\n",
    "Note that, we might often see the use of t-test with random variables that are not extended to infinity, such as test scores. The test is still approximate acceptable if the variables are well distributed within the defined range, such as the density around the boundary is significantly low. If this is the case, one method we can apply is to transform the variables to a well defined range before performing the test. However, we will not cover this complication in this lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "'{0:.0f}'.format(sample_size - 1)": "64",
     "'{0:.2f}'.format(alpha)": "0.05",
     "'{0:.2f}'.format(alpha*100)": "5.00",
     "'{0:.3f}'.format(tcrit)": "-1.998",
     "'{0:.3f}'.format(tscore[0])": "-8.121",
     "'{0}'.format(alpha/2)": "0.025",
     "alpha": "0.05",
     "pop_mean": "50.0",
     "pop_std**2": "100.0",
     "sample_size": "65",
     "test_mean": "60.0"
    }
   },
   "source": [
    "## Is the Sample Mean Indifference to {{test_mean}}?\n",
    "\n",
    "Our current question we will work on is to verify when the sample mean is indifference to {{test_mean}}. This kind of question, together with the nature of the data, is suitable to be tested with one-sample t-test, because the test compares one sample with a target value.\n",
    "\n",
    "we will perform the t-test by using the simulated data presented above, which are randomly drawn i.i.d. from a normal distribution with mean {{pop_mean}} and variance {{pop_std**2}}. Note that we do not need to know the original data, because we require only the sample mean, variance, and size. These values are stated below the histogram.\n",
    "\n",
    "To perform the test, we follow this recipe of 5 steps.\n",
    "\n",
    "### 0. Set up hypothesis\n",
    "\n",
    "The hypothesis of this scenario is as following:\n",
    "\n",
    "$H_0$: $\\bar{x}$ = {{test_mean}}\n",
    "\n",
    "\n",
    "$H_1$: $\\bar{x}$ $\\neq$ {{test_mean}}\n",
    "\n",
    "where $H_0$ is called a null hypothesis, $H_1$ is called an alternative hypothesis, and $\\bar{x}$ is the sample mean. To explain why the hypothesis must be like this, i.e., not $H_1$: $\\bar{x}$ = {{test_mean}} for example, we will have to go through the philosophy underlying, which we will not discuss here. In practice, the trick is to set an argument with equality as the null hypothesis, and any inequality (also including greater and less than) as the alternative one.\n",
    "\n",
    "### 1. Calculate sample t score\n",
    "\n",
    "The sample t score is defined as\n",
    "$$\n",
    "t = \\frac{\\bar{x} - \\mu}{\\frac{s}{\\sqrt{N}}}\n",
    "$$\n",
    "where $\\bar{x}$ is the sample mean, $\\mu$ is the target value we are comparing to, i.e., $\\mu = 60$ in this case, $s$ is the sample standard deviation, and $N$ is the sample size. The greater the sample t score deviating from zero implies the more likely that the null hypothesis will be rejected. Note that the sample t score is affected by both the difference $\\bar{x} - \\mu$ itself, and the dispersion term at the denominator $\\frac{s}{\\sqrt{N}}$. The denominator term simply tells us as, if the dispersion of the sample is large, it is unlikely that we can state the difference between $\\bar{x}$ and $\\mu$, i.e., unlikely to reject the null hypothesis. In our case, the sample t score is {{'{0:.3f}'.format(tscore[0])}}.\n",
    "\n",
    "### 2. Choose significance level\n",
    "\n",
    "As mentioned earlier, a hypothesis testing is performed in order to verify what conclusion should be made regarding to the properties of the data, and at how much likelihood that the conclusion might be wrong. The significance level, $\\alpha$, represents the likelihood of making a wrong conclusion. To be precise, what we are doing here is to find evidence from the data that we can reject the null hypothesis given the acceptable rate of error $\\alpha$. In other words, this is the Type I error occurred when rejecting a null hypothesis that is actually true, or a false positive (since we typically consider the alternative hypothesis as a positive outcome). We note that the test is not involved with Type II, or $\\beta$, error that states the error from failing to reject a null hypothesis that is actually false, or false negative. Again, the underlying reason for this comes from the philosophy of the test.\n",
    "\n",
    "In practice, we simply choose $\\alpha$ as how much the rate of error from a false positive would be acceptable. Let's say we choose $\\alpha = ${{'{0:.2f}'.format(alpha)}}. It means that, if we reject the null hypothesis, there is {{'{0:.2f}'.format(alpha*100)}}% chance that the null hypothesis is actually correct.\n",
    "\n",
    "### 3. Calculate the critical t score\n",
    "\n",
    "The probability density function (PDF) of the t-distribution is defined by $P(x|\\nu)$ where $P(\\cdot)$ is the t-distribution PDF, $x$ is the random variable, and $\\nu = N-1$ is the degrees of freedom. The t-distribution is a symmetric bell-shaped distribution that has bigger wings than the normal distribution. The t-distribution is converged to the normal distribution at the limit $\\nu$ to infinity.\n",
    "\n",
    "For our purpose here, we would like to identify the critical t score $t_{crit}$ corresponding with the significance level, degrees of freedom, and hypothesis. According to the alternative hypothesis that we specify as an inequality sign, this is a 2-tailed hypothesis, i.e., we are interested in both negative and positive sides of the distribution. Since the significance level defines the total acceptable error, in the 2-tailed hypothesis we find the $t_{crit}$ on one side by considering $\\alpha/2$. This is also correct due to the symmetry of the t-distribution. Therefore, in our case that $\\alpha = ${{'{0:.2f}'.format(alpha)}}, $N = ${{sample_size}}, with 2-tailed hypothesis, we look up in the t-distribution table given $\\nu = ${{'{0:.0f}'.format(sample_size - 1)}} for a t score that gives us {{'{0}'.format(alpha/2)}} cumulative probability (i.e., area under the PDF curve from negative infinity to the t score). We get $t_{crit} =${{'{0:.3f}'.format(tcrit)}}.\n",
    "\n",
    "### 4. Compare the t score and the critical t score, and make a conclusion\n",
    "\n",
    "Given the 2-tailed hypothesis, the critical t score separates the space of values into two regions: reject the null hypothesis if $|t| > |t_{crit}|$, or fail to reject the null hypothesis otherwise. In our case, we have $|t| > |t_{crit}|. Therefore, we conclude that \"we reject the null hypothesis given the significance level {{alpha}}.\" \n",
    "\n",
    "Note that, the conclusion statement must always include the significance level for the claim. Moreover, to be statistically correct, the claim can either be \"reject\" or \"fail to reject\" the null hypothesis, which is not the same as saying \"accept.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "'{0:.2f}'.format(confidence_interval[0])": "48.20",
     "'{0:.2f}'.format(confidence_interval[1])": "52.86",
     "'{0:.3E}'.format(tscore[1])": "1.975E-11",
     "'{0:.3E}'.format(tscore[1]/2)": "9.877E-12",
     "(1-alpha)*100": "95.0",
     "alpha": "0.05",
     "test_mean": "60.0"
    }
   },
   "source": [
    "## Alternative Testing: Confidence Interval and p-Value\n",
    "\n",
    "In the previous testing, we aim to compare between the sample t score and the critical t score. There are other ways that we can reach the same conclusion by considering different statistics. Here, we discuss testing by constructing a confidence interval, and by applying a p-value.\n",
    "\n",
    "### Confidence interval\n",
    "\n",
    "A confidence interval (CI) tells us how much likely that a randomly drawn variable would be inside the interval. For example, if we have a 95% CI from [0,10] that is extended from the sample mean 5, it implies that we are 95% certain that a randomly drawn variable would be some value between 0 to 10. Therefore, in term of hypothesis testing, we can say that the sample mean is indifference to 5 with 95% certainty (or 5% error).\n",
    "\n",
    "The idea of constructing a confidence interval (CI) for a hypothesis testing is that we expand from the sample mean to be a range of values. The size of the range is determined by the significance level, and the sample size and variance. To be precise, for the t-statistics, the size of the range is \n",
    "$$\n",
    "| x - \\bar{x} | = |t_{crit}| \\frac{s}{\\sqrt{N}}\n",
    "$$\n",
    "We conclude that \"there is no statistical difference between the sample mean and the target value (or fail to reject $H_0$) with (1 - $\\alpha$)$\\times$100\\% confidence level,\" if the target value is inside the range, and vice versa.\n",
    "\n",
    "In our case, the {{(1-alpha)*100}}% CI is [{{'{0:.2f}'.format(confidence_interval[0])}},{{'{0:.2f}'.format(confidence_interval[1])}}]. Since the target value {{test_mean}} is not inside the interval, we can conclude that we reject the null hypothesis at the 95% confidence level.\n",
    "\n",
    "### p-value\n",
    "\n",
    "The p-value is another test statistics that can be interpreted as how much likely that the null hypothesis is true. This method is actually easier to perform as well as to interpret the result than the previously introduced methods.\n",
    "\n",
    "To calculate the p-value, we only need the sample t score. Look up for the tail cumulative probability given the sample t score, i.e., P(|sample t score| $\\leq$ t $< \\infty$) $\\approx$ {{'{0:.3E}'.format(tscore[1]/2)}} in our case. Since our hypothesis is 2-tailed, we sum the tail probability from both sides, which is equivalent to multiplying by a factor of 2 to one tail because of symmetry. This is our p-value = {{'{0:.3E}'.format(tscore[1])}}, which means there is {{'{0:.3E}'.format(tscore[1])}} chance that the null hypothesis would be true.\n",
    "\n",
    "Then, we choose the significance level $\\alpha$, which is {{alpha}} in this example. Since the significance level is the maximum acceptable error rate we allow, if p-value $< \\alpha$, we reject null hypothesis at the chosen significance level. In our case {{'{0:.3E}'.format(tscore[1])}} $<$ {{alpha}}, so we reject the null hypothesis at {{alpha}} significance level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Routines\n",
    "\n",
    "The python routines to perform the t-test are shown in the code cell above. We perform the calculate by using routines provided in scipy.stats (Note: we use the statement \"from scipy import stats\" in the preamble), which are briefly summarized here.\n",
    "\n",
    "- Calculate sample t score: stats.ttest_1samp(sample,test_mean), this is the routine that directly performs one-sample t-test. The first argument is an array of sample data, and the second argument is the target value. This routine is very handy because it returns both sample t score and p-value. Therefore, we can directly use the p-value to make a conclusion statement.\n",
    "\n",
    "- Calculate critical t score: stats.t.ppf(alpha/2,sample_size-1), this routine performs the inverse of the cumulative t-distribution function, i.e., given the left tail probability (the first argument), and degrees of freedom (the second argument), the routine returns the t score corresponding to the input arguments. Note that, the tail probability is alpha/2 because we set a 2-tailed hypothesis.\n",
    "\n",
    "- Calculate a confidence interval: stats.t.interval(1-alpha, sample_size-1, loc=sample_mean, scale=np.sqrt(sample_var/sample_size)), the input arguments are the confidence level 1-alpha, degrees of freedom, the sample mean (which is the center of the expansion), and the dispersion term as the denominator in the t score formula. This routine returns the both lower and upper limits of the 1-$\\alpha$ CI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Notes\n",
    "\n",
    "In this lecture, we learn how to statistically make a decision and estimate the probability of being wrong regarding to the available data by applying statistical hypothesis testing. The one-sample t-test is introduced as the method appropriate to deal with a problem comparing the properties of one sample to a target value. Assumptions are discussed, and emphasized that they must be approximately satisfied for the method to be valid. We then perform the t-test by following the recipe: setting up hypothesis, calculating sample t score, choosing significance level, calculating critical t score, and comparing the t scores for the conclusion. Moreover, we learn how to construct a confidence interval and calculate p-value, which both of them can also be used to make a conclusion and are consistent with the first method comparing t scores. Again, it is emphasized that the conclusion statement is to say either \"reject\" or \"fail to reject\" the null hypothesis with the chosen significance level. Last, we discuss the python routines to perform this test.\n",
    "\n",
    "A couple of points are worth noting. First, we set up a 2-tailed hypothesis in our example. For a 1-tailed hypothesis, we still follow the same recipe, but the test statistics, i.e., the critical t value, CI, and p-value will be slightly change in the formula and when to interpret rejecting the null hypothesis. Second, this recipe and the idea behind it is quite generalized that can be applied to other types of hypothesis testing. Precisely, in order to perform a hypothesis testing, we first need to have a dataset that at least approximately satisfies the underlying assumptions of the test we are using. Then, we try to calculate a statistic score representing the dataset, then compare it the a test score representing the acceptable error rate. Therefore, students should have this hypothesis testing framework in mind, so that they can extend to understand other types of the test easily. \n",
    "\n",
    "Last, the meaning of Type I $\\alpha$ and Type II $\\beta$ errors can be interpreted in the terms of precision/recall. By definition of the error types, we can construct the contingency table as P(prediction | outcome):\n",
    "\n",
    "- P(reject null | null false) = 1 - $\\beta$, P(reject null | null true) = $\\alpha$\n",
    "- P(not reject null | null false) = $\\beta$, P(not reject null | null true) = 1 - $\\alpha$\n",
    "\n",
    "Therefore, by treating null as a negative case, we can associate the errors with precision/recall as:\n",
    "\n",
    "- Precision (or positive predictive value) = true positive / positive prediction = $\\frac{1 - \\beta}{1 - \\beta + \\alpha}$\n",
    "- Recall (or sensitivity) = true positive / positive outcome = $\\frac{1 - \\beta}{1 - \\beta + \\beta}$ = 1 - $\\beta$\n",
    "\n",
    "Note that, the test aims to reject the null hypothesis, therefore Type I error $\\alpha$ is associated with it, and this has nothing to do with Type II error $\\beta$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "'{0:.2f}'.format(beta)": "0.93",
     "'{0:.2f}'.format(beta*100)": "92.77",
     "'{0:.2f}'.format(confidence_interval[0])": "48.20",
     "'{0:.2f}'.format(confidence_interval[1])": "52.86",
     "'{0:.3f}'.format(np.absolute(tcrit))": "1.998",
     "'{0:.3f}'.format(tscore_beta_left)": "-1.543",
     "'{0:.3f}'.format(tscore_beta_right)": "2.452",
     "pop_mean": "50.0"
    }
   },
   "source": [
    "## Additional Materials: Calculate $\\beta$\n",
    "\n",
    "We discuss how to calculate Type II $\\beta$ error here. To calculate $\\beta$, the population mean is required, which in practice we actually do not have this information. However, let's say we assume the population mean {{pop_mean}}. Then, given our null hypothesis, $\\beta =$ P(not reject $\\mu = 60$ | null false, i.e., $\\mu \\neq 60$) = P(not reject $\\mu = 60$ | $\\mu =$ {{pop_mean}}). Note that, we substitute the condition with the assumed population mean which is valid because {{pop_mean}} makes the null false. \n",
    "\n",
    "From the previous calculation, we set the rejection regions to be |t| $\\geq$ {{'{0:.3f}'.format(np.absolute(tcrit))}}. Since it is easier to work on the data unit instead of t score when it comes to calculating $\\beta$, we invert the critical t scores on both sides to values in the data unit as: $x = \\bar{x} + \\frac{s}{\\sqrt{N}}t$, which is actually equiavlent to the calculated CI. Therefore, the rejection regions in the data unit is when $x <${{'{0:.2f}'.format(confidence_interval[0])}} or $x >${{'{0:.2f}'.format(confidence_interval[1])}}.\n",
    "\n",
    "Now, we can re-express the error $\\beta =$ P(not reject $\\mu = 60$ | $\\mu =$ {{pop_mean}}) = P({{'{0:.2f}'.format(confidence_interval[0])}} $\\leq$ x $\\leq$ {{'{0:.2f}'.format(confidence_interval[1])}} | $\\mu =$ {{pop_mean}}). Then, we calculate this probability as if it is a t-distribution centered at {{pop_mean}} with scaled dispersion $s / \\sqrt{N}$. We get P({{'{0:.2f}'.format(confidence_interval[0])}} $\\leq$ x $\\leq$ {{'{0:.2f}'.format(confidence_interval[1])}} | $\\mu =$ {{pop_mean}}) = P({{'{0:.3f}'.format(tscore_beta_left)}} $\\leq$ t $\\leq$ {{'{0:.3f}'.format(tscore_beta_right)}}) = {{'{0:.2f}'.format(beta)}}, implying that the error rate from failing to reject null when null false is {{'{0:.2f}'.format(beta*100)}}%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
